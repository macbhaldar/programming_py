col1, col2, col3, col4, col5, col6, col7, col8 = st.columns(8)
with col1:
st.button('Generate Randomized')
with col2:
recommend = st.button('Recommend')
if recommend:
try:
SpacyParser = SpacyParser()                                  # instantiate class object with parameter set to false
original_df['parsed_product'] = SpacyParser.transform(df)
shopping_cart['parsed_product'] = SpacyParser.transform(shopping_cart)
cart_category_list = list(shopping_cart.parsed_product)
recommendation_cart = pd.DataFrame(columns=original_df.columns)
try:
for item in cart_category_list:
# initiate search of parsed product from first row of generated shopping cart
# rules[rules.item_A.str.contains(item, case=False)] # dataframe of rules containing the parsed_product of the generated shopping cart
index = rules[rules.item_A.str.contains(item, case=False)].index # index of rules containing parsed_product of the generated shopping cart
itemb = list(rules.loc[index, 'item_B'])[int(np.random.randint(9, size=1))] # picks randomly from the top 5 associations of confidence
recommendation_cart = pd.concat([recommendation_cart,original_df[original_df['parsed_product'] == itemb].sample(1)])
except Exception as e:
print(e)
st.warning('generate a shopping cart to create a recommendation')
st.write(shopping_cart.style.background_gradient(cmap=cm).set_precision(2))
st.markdown('You may also be interested in...')
st.write(recommendation_cart.style.background_gradient(cmap=cm).set_precision(2))
except:
st.warning('Generate a shopping cart to make recommendations')
else:
try:
st.write(shopping_cart.style.background_gradient(cmap=cm).set_precision(2))
except Exception:
pass
# Dataset search feature----------------------------------------------------------#
with st.expander("Search 'on-sale' data at " + str(location)):
search_input = st.text_input('Enter items as ("Pasta, Chocolate") format', key=2)
if search_input:
original_df = df.copy()
search_input.split(', ')
r = search_input.replace(', ','|')
st.write(original_df.loc[original_df['product'].str.contains(r,case=False)].style.background_gradient(cmap=cm).set_precision(2))
st.button('Search', key=3)
# Dataset download feature--------------------------------------------------------#
with st.expander("Download 'on-sale' data at " + str(location) + " as a CSV File/Excel Spreadsheet"):
#### Download Parsed Data Frame Button
if platform.system()=='Windows':
excel_download_string = str(pathlib.Path(queryselection)).replace('scraped products dump\location', '')
excel_download_string = excel_download_string
excel_download_string = excel_download_string.replace('.pkl', '') + '.csv'
else:
excel_download_string = str(pathlib.Path(queryselection)).replace('Deployment/scraped products dump/location', '')
excel_download_string = excel_download_string
excel_download_string = excel_download_string.replace('.pkl', '') + '.csv'
@st.cache
def convert_df(df):
return df.to_csv().encode('utf-8')
csv = convert_df(df)
st.download_button(
"Download as CSV",
csv,
excel_download_string,
"text/csv",
key='download-csv'
)
###################################################################################
View(handle)
View(templates)
templates
library(tidyverse)
library(ggrepel)
housing = read_csv("https://statistics.gov.scot/slice/observations.csv?&dataset=http%3A%2F%2Fstatistics.gov.scot%2Fdata%2Flocal-authority-housing-stock-by-type&http%3A%2F%2Fpurl.org%2Flinked-data%2Fcube%23measureType=http%3A%2F%2Fstatistics.gov.scot%2Fdef%2Fmeasure-properties%2Fcount&http%3A%2F%2Fstatistics.gov.scot%2Fdef%2Fdimension%2FtypeOfDwelling=http%3A%2F%2Fstatistics.gov.scot%2Fdef%2Fconcept%2Ftype-of-dwelling%2Fall", skip = 7) %>%
rename(id = `http://purl.org/linked-data/sdmx/2009/dimension#refArea`) %>%
pivot_longer(!c(`Reference Area`, id), names_to = "year", values_to = "homes")
require(plotrix)
names<-c("A","B","C","D","E","F","G","H","I","J")
p<-c(76.7,90,73.5,84.2,91.6,80.6,64.2,46.9,37.4)
std<-c(80,95,80,90,90,80,95,90,70,75)
pi <- 4*(4*atan(1/5)-atan(1/239))
N<-length(names)
gap <- std-p
rad <- rep(NA,N)
rad[gap<=0] <- 4 + 29 * (1-abs(gap[gap<=0])/(100-std[gap<=0]))
rad[gap>0]  <- 33 + 67 * (gap[gap>0] / std[gap>0])
jpeg(“target.jpg”,width=1200,height=900,res=100, quality=100)
require(plotrix)
require(plotrix)
names<-c("A","B","C","D","E","F","G","H","I","J")
p<-c(76.7,90,73.5,84.2,91.6,80.6,64.2,46.9,37.4)
std<-c(80,95,80,90,90,80,95,90,70,75)
pi <- 4*(4*atan(1/5)-atan(1/239))
N<-length(names)
gap <- std-p
rad <- rep(NA,N)
rad[gap<=0] <- 4 + 29 * (1-abs(gap[gap<=0])/(100-std[gap<=0]))
rad[gap>0]  <- 33 + 67 * (gap[gap>0] / std[gap>0])
jpeg(“target.jpg”,width=1200,height=900,res=100, quality=100)
require(plotrix)
names<-c("A","B","C","D","E","F","G","H","I","J")
p<-c(76.7,90,73.5,84.2,91.6,80.6,64.2,46.9,37.4)
std<-c(80,95,80,90,90,80,95,90,70,75)
pi <- 4*(4*atan(1/5)-atan(1/239))
N<-length(names)
gap <- std-p
rad <- rep(NA,N)
rad[gap<=0] <- 4 + 29 * (1-abs(gap[gap<=0])/(100-std[gap<=0]))
rad[gap>0]  <- 33 + 67 * (gap[gap>0] / std[gap>0])
jpeg(“target.jpg”,width=1200,height=900,res=100, quality=100)
if(!require(pacman))install.packages("pacman")
pacman::p_load('dplyr', 'tidyr', 'gapminder',
'ggplot2',  'ggalt',
'forcats', 'R.utils', 'png',
'grid', 'ggpubr', 'scales',
'bbplot')
#Data for chart from gapminder package
line_df <- gapminder %>%
filter(country == "Malawi")
#Make plot
line <- ggplot(line_df, aes(x = year, y = lifeExp)) +
geom_line(colour = "#1380A1", size = 1) +
geom_hline(yintercept = 0, size = 1, colour="#333333") +
bbc_style() +
labs(title="Living longer",
subtitle = "Life expectancy in Malawi 1952-2007")
theme(panel.grid.major.x = element_line(color="#cbcbcb"),
panel.grid.major.y=element_blank())
finalise_plot(plot_name = my_line_plot,
source = "Source: Gapminder",
save_filepath = "filename_that_my_plot_should_be_saved_to.png",
width_pixels = 640,
height_pixels = 450,
logo_image_path = "placeholder.png")
library(tidyverse)
library(ggxmean)
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(e1071, tidyverse, caret, rmarkdown,
corrplot, readxl, ModelMetrics, fpp2,expsmooth,CombMSC)
library(tidyverse)
library(lubridate)
# Read in the crime data
crime_raw <- read_csv("data/Violent_Crime_by_County_1975_to_2016.csv")
# Select and mutate columns the needed columns
crime_use <- crime_raw %>%
select(JURISDICTION, YEAR, POPULATION, crime_rate = `VIOLENT CRIME RATE PER 100,000 PEOPLE`) %>%
mutate(YEAR_2 = year(mdy_hms(YEAR)))
# Peek at the data
head(crime_use)
# Plot the data as lines and linear trend lines
ggplot(crime_use, aes(x = YEAR_2, y = crime_rate, group = JURISDICTION)) +
geom_line() +
geom_smooth(method = "lm", se = FALSE, size = 0.5)
# Mutate data to create another year column, YEAR_3
crime_use <- crime_use %>%
mutate(YEAR_3 = YEAR_2 - min(YEAR_2))
head(crime_use)
library(lmerTest)
# Build a lmer and save it as lmer_crime
lmer_crime <- lmer(crime_rate ~ YEAR_3 + (YEAR_3|JURISDICTION), crime_use)
# Rename crime_names county
county_slopes  <- county_slopes  %>%
mutate(county = ifelse(county == "Baltimore City", "Baltimore city", county))
# Merging data frames
# Merge the map and slope data frames
both_data <-
full_join(county_map, county_slopes)
# Peek at the data
head(both_data)
# Mapping trends
# Set the notebook's plot settings
options(repr.plot.width=10, repr.plot.height=5)
# Plot the results
crime_map <-
ggplot(both_data, aes(long, lat, group = county, fill = YEAR_3)) +
geom_polygon() +
scale_fill_continuous(name = expression(atop("Change in crime rate","(Number year"^-1*")")),
low = "skyblue", high = "gold")
# Look at the map
crime_map
# Plot options
options(repr.plot.width=10, repr.plot.height=5)
# Polish figure
crime_map_final <- crime_map +
theme_minimal() +
xlab("") +
ylab("") +
theme(axis.line=element_blank(),
axis.text=element_blank(),
panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
panel.border=element_blank(),
panel.background=element_blank())
# Look at the map
print(crime_map_final)
# Compare populations and crime rates
# Build a lmer with both year and population
lmer_pop <- lmer(crime_rate ~ YEAR_3 + POPULATION + (YEAR_3|JURISDICTION), data=crime_use)
# Inspect the results
summary(lmer_pop)
ranef(lmer_pop)
library(TidyDensity)
library(dplyr)
library(purrr)
library(rbenchmark)
x <- mtcars$mpg
n <- length(x)
times <- 2000L
prop <- .8
size <- floor(n * prop)
benchmark(
"TidyDensity" = {
te <- tidy_bootstrap(.x = x, .num_sims = times, .proportion = prop) %>%
bootstrap_unnest_tbl()},
"PieceWise_Purr" = {
idx <- map(rep(n, times), sample, size, replace = TRUE)
l <- map(idx, ~x[.x] %>% as_tibble())
ldf <- imap(l, ~ bind_cols(.x, sim_number = factor(.y))) %>%
map_df(as_tibble)},
"Modified_Single_Purrr" + {
df_tbl <- map(rep(n, times), sample, size = size, replace = TRUE) %>%
map(~ x[.x]) %>%
imap(~ cbind(.x, sim_number = factor(.y))) %>%
map_df(as_tibble)},
replications = 1000,
columns = c("test", "replications", "elapsed", "relative", "user.self", "sys.self"))
View(df_tbl)
library(rvest)
link <- read_html("https://www.moneycontrol.com/stocks/marketstats/indexcomp.php?optex=NSE&opttopic=indexcomp&index=9")
link %>%
html_node("title") %>%
html_text()
urls <-  link %>%
html_node(xpath = '//*[@id="mc_mainWrapper"]/div[3]/div[1]/div[6]/div[2]/div/table') %>%
html_table()
dim(urls)
dim(urls)
length(stock_list)
reticulate::repl_python()
from nsepy import get_history
from nsepy import get_history
from nsepy import get_history
from datetime import date
data = get_history(symbol="KHAITANLTD", start=date(2022,1,1), end=date(2022,11,10))
View(data)
write.csv(data,"KHAITAN.csv", row.names = FALSE)
write.csv(data,"KHAITAN.csv", row.names == FALSE)
write.csv(data,"KHAITAN.csv")
library(readr)
library("readr)
library("readr")
library(readr)
library(data.table)
fwrite(data, "data.csv")
data.to_csv('KHAITAN.csv')
quit
library(data.table)
fwrite(data, "data.csv")
import numpy as np
reticulate::repl_python()
import numpy as np
import numpy as np
import pandas as pd
import yfinance as yf
import warnings
import cufflinks as cf
import plotly.graph_objects as go
from plotly.offline import iplot, init_notebook_mode
import matplotlib.pyplot as plt
cf.go_offline()
init_notebook_mode()
TICKER = "AAPL"
df = yf.download(TICKER,
start="2021-01-01",
end="2021-05-30")
df["Close"].plot(title=f"{TICKER}'s stock price");
qf = cf.QuantFig(df, title="Apple's stock price in 2021", name='AAPL')
qf.iplot()
fig = go.Figure(data=
[go.Candlestick(x=df.index,
open=df["Open"],
high=df["High"],
low=df["Low"],
close=df["Close"])]
)
fig.update_layout(
title=f"{TICKER}'s adjusted stock price",
yaxis_title="Price ($)"
)
fig.show()
qf = cf.QuantFig(df, title="Apple's stock price in 2021", name='AAPL')
qf.add_sma(periods=14, column='Close', color='blue')
qf.iplot()
qf = cf.QuantFig(df, title="Apple's stock price in 2021", name='AAPL')
qf.add_sma([10, 50], width=2, color=['blue', 'red'])
qf.add_rsi(periods=14, color='green')
qf.add_bollinger_bands(periods=20, boll_std=2 ,colors=['orange','grey'], fill=True)
qf.add_volume()
qf.add_macd()
qf.iplot()
library(ggplot2)
library(maptools)
library(rgeos)
library(ggmap)
library(scales)
library(RColorBrewer)
set.seed(8000)
shp <- readShapeSpatial('~/Dropbox/PhD_Arka/Exploratory Indian Data Analysis/India Shapefile With Kashmir/india_shapefile_git/Admin2.shp')
library(ggplot2)
library(maptools)
library(rgeos)
library(ggmap)
library(scales)
library(RColorBrewer)
set.seed(8000)
shp <- readShapeSpatial('~/Dropbox/PhD_Arka/Exploratory Indian Data Analysis/India Shapefile With Kashmir/india_shapefile_git/Admin2.shp')
setwd("~/Python-Files/floodfill")
from PIL import Image, ImageDraw
reticulate::repl_python()
from PIL import Image, ImageDraw
img = Image.open("shape.png")
img = img.convert("RBG")
target_pixel = (420, 270)
target_color = (255, 255, 0)
ImageDraw.floodfill(img, target_pixel, target_color, thresh=0.5)
img.show()
# Python3 program to implement
# flood fill algorithm
# Dimensions of paint screen
M = 8
N = 8
# A recursive function to replace
# previous color 'prevC' at '(x, y)'
# and all surrounding pixels of (x, y)
# with new color 'newC' and
def floodFillUtil(screen, x, y, prevC, newC):
# Base cases
if (x < 0 or x >= M or y < 0 or
y >= N or screen[x][y] != prevC or
screen[x][y] == newC):
return
# Replace the color at (x, y)
screen[x][y] = newC
# Recur for north, east, south and west
floodFillUtil(screen, x + 1, y, prevC, newC)
floodFillUtil(screen, x - 1, y, prevC, newC)
floodFillUtil(screen, x, y + 1, prevC, newC)
floodFillUtil(screen, x, y - 1, prevC, newC)
# It mainly finds the previous color on (x, y) and
# calls floodFillUtil()
def floodFill(screen, x, y, newC):
prevC = screen[x][y]
if(prevC==newC):
return
floodFillUtil(screen, x, y, prevC, newC)
# Driver Code
screen = [[1, 1, 1, 1, 1, 1, 1, 1],
[1, 1, 1, 1, 1, 1, 0, 0],
[1, 0, 0, 1, 1, 0, 1, 1],
[1, 2, 2, 2, 2, 0, 1, 0],
[1, 1, 1, 2, 2, 0, 1, 0],
[1, 1, 1, 2, 2, 2, 2, 0],
[1, 1, 1, 1, 1, 2, 1, 1],
[1, 1, 1, 1, 1, 2, 2, 1]]
x = 4
y = 4
newC = 3
floodFill(screen, x, y, newC)
print ("Updated screen after call to floodFill:")
for i in range(M):
for j in range(N):
print(screen[i][j], end = ' ')
print()
# This code is contributed by Ashutosh450
# Updated by Arun Pandey
# Python3 program for above approach
# Function to check valid coordinate
def validCoord(x, y, n, m):
if x < 0 or y < 0:
return 0
if x >= n or y >= m:
return 0
return 1
# Function to run bfs
def bfs(n, m, data, X, Y, color):
# Visiting array
vis = [[0 for i in range(101)] for j in range(101)]
# Creating queue for bfs
obj = []
# Pushing pair of {x, y}
obj.append([X, Y])
# Marking {x, y} as visited
vis[X][Y] = 1
# Until queue is empty
while len(obj) > 0:
# Extracting front pair
coord = obj[0]
x = coord[0]
y = coord[1]
preColor = data[x][y]
data[x][y] = color
# Popping front pair of queue
obj.pop(0)
# For Upside Pixel or Cell
if validCoord(x + 1, y, n, m) == 1 and vis[x + 1][y] == 0 and data[x + 1][y] == preColor:
obj.append([x + 1, y])
vis[x + 1][y] = 1
# For Downside Pixel or Cell
if validCoord(x - 1, y, n, m) == 1 and vis[x - 1][y] == 0 and data[x - 1][y] == preColor:
obj.append([x - 1, y])
vis[x - 1][y] = 1
# For Right side Pixel or Cell
if validCoord(x, y + 1, n, m) == 1 and vis[x][y + 1] == 0 and data[x][y + 1] == preColor:
obj.append([x, y + 1])
vis[x][y + 1] = 1
# For Left side Pixel or Cell
if validCoord(x, y - 1, n, m) == 1 and vis[x][y - 1] == 0 and data[x][y - 1] == preColor:
obj.append([x, y - 1])
vis[x][y - 1] = 1
# Printing The Changed Matrix Of Pixels
for i in range(n):
for j in range(m):
print(data[i][j], end = " ")
print()
print()
n = 8
m = 8
data = [
[ 1, 1, 1, 1, 1, 1, 1, 1 ],
[ 1, 1, 1, 1, 1, 1, 0, 0 ],
[ 1, 0, 0, 1, 1, 0, 1, 1 ],
[ 1, 2, 2, 2, 2, 0, 1, 0 ],
[ 1, 1, 1, 2, 2, 0, 1, 0 ],
[ 1, 1, 1, 2, 2, 2, 2, 0 ],
[ 1, 1, 1, 1, 1, 2, 1, 1 ],
[ 1, 1, 1, 1, 1, 2, 2, 1 ],
]
x, y, color = 4, 4, 3
# Function Call
bfs(n, m, data, x, y, color)
# This code is contributed by decode2207.
quit
setwd("~/Github-Repo/programming_py/matrix_data_structure/floodfill")
# Function to check valid coordinate
def validCoord(x, y, n, m):
# flood fill algorithm using recursion
# Dimensions of paint screen
M = 8
N = 8
# A recursive function to replace previous color 'prevC' at '(x, y)' and all surrounding pixels of (x, y) with new color 'newC' and
def floodFillUtil(screen, x, y, prevC, newC):
reticulate::repl_python()
# Function to check valid coordinate
def validCoord(x, y, n, m):
if x < 0 or y < 0:
return 0
if x >= n or y >= m:
return 0
return 1
# Function to run bfs
def bfs(n, m, data, X, Y, color):
# Visiting array
vis = [[0 for i in range(101)] for j in range(101)]
# Creating queue for bfs
obj = []
# Pushing pair of {x, y}
obj.append([X, Y])
# Marking {x, y} as visited
vis[X][Y] = 1
# Until queue is empty
while len(obj) > 0:
# Extracting front pair
coord = obj[0]
x = coord[0]
y = coord[1]
preColor = data[x][y]
data[x][y] = color
# Popping front pair of queue
obj.pop(0)
# For Upside Pixel or Cell
if validCoord(x + 1, y, n, m) == 1 and vis[x + 1][y] == 0 and data[x + 1][y] == preColor:
obj.append([x + 1, y])
vis[x + 1][y] = 1
# For Downside Pixel or Cell
if validCoord(x - 1, y, n, m) == 1 and vis[x - 1][y] == 0 and data[x - 1][y] == preColor:
obj.append([x - 1, y])
vis[x - 1][y] = 1
# For Right side Pixel or Cell
if validCoord(x, y + 1, n, m) == 1 and vis[x][y + 1] == 0 and data[x][y + 1] == preColor:
obj.append([x, y + 1])
vis[x][y + 1] = 1
# For Left side Pixel or Cell
if validCoord(x, y - 1, n, m) == 1 and vis[x][y - 1] == 0 and data[x][y - 1] == preColor:
obj.append([x, y - 1])
vis[x][y - 1] = 1
# Printing The Changed Matrix Of Pixels
for i in range(n):
for j in range(m):
print(data[i][j], end = " ")
print()
print()
n = 8
m = 8
data = [
[ 1, 1, 1, 1, 1, 1, 1, 1 ],
[ 1, 1, 1, 1, 1, 1, 0, 0 ],
[ 1, 0, 0, 1, 1, 0, 1, 1 ],
[ 1, 2, 2, 2, 2, 0, 1, 0 ],
[ 1, 1, 1, 2, 2, 0, 1, 0 ],
[ 1, 1, 1, 2, 2, 2, 2, 0 ],
[ 1, 1, 1, 1, 1, 2, 1, 1 ],
[ 1, 1, 1, 1, 1, 2, 2, 1 ],
]
x, y, color = 4, 4, 3
# Function Call
bfs(n, m, data, x, y, color)
